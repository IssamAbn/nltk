{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36ec4156",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = [        \n",
    "\"\"\"Perhaps one of the most significant advances made by Arabic mathematics began at this time with the work of al-Khwarizmi, namely\n",
    "the beginnings of algebra. It is important to understand just how significant this new idea was. It was a revolutionary move away from\n",
    "the Greek concept of mathematics which was essentially geometry. Algebra was a unifying theory which allowed rational\n",
    "numbers, irrational numbers, geometrical magnitudes, etc., to all be treated as \"algebraic objects\". It gave mathematics a whole new\n",
    "development path so much broader in concept to that which had existed before, and provided a vehicle for future development of the\n",
    "subject. Another important aspect of the introduction of algebraic ideas was that it allowed mathematics to be applied to itself in a\n",
    "way which had not happened before.\"\"\",\n",
    "\n",
    " \"\"\"ربما كانت أحد أهم التطورات التي قامت بها الرياضيات العربية التي بدأت في هذا الوقت بعمل الخوارزمي  وهي بدايات الجبر،ومن المهم فهم كيف كانت هذه الفكرة الجديدة مهمة، فقد كانت خطوة ثورية بعيدا عن\n",
    "المفهوم اليوناني للرياضيات التي هي في جوهرها  هندسة، الجبركان نظرية موحدة تتحيح الأعداد الكسرية و الأعداد اللا كسرية ، والمقادير الهندسية و غيرها ، أن تتعامل على أنها أجسام جبرية، و أعطت الرياضيات ككل مسارا جديدًا للتطوربمفهوم \n",
    " أوسع بكثير من الذي كان موجودًا من قبل ، وقدم وسيلة للتنمية في هذا الموضوع مستقبلا .و جانب آخر مهم لإدخال أفكار الجبر و هو أنه سمح بتطبيق الرياضيات على نفسها \n",
    "بطريقة  لم تحدث من قبل.\"\"\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5da328e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\issam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\issam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ''' + string.punctuation  #all punctuations \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "134cc3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['perhaps', 'one', 'of', 'the', 'most', 'significant', 'advances', 'made', 'by', 'arabic', 'mathematics', 'began', 'at', 'this', 'time', 'with', 'the', 'work', 'of', 'alkhwarizmi', 'namely', 'the', 'beginnings', 'of', 'algebra', 'it', 'is', 'important', 'to', 'understand', 'just', 'how', 'significant', 'this', 'new', 'idea', 'was', 'it', 'was', 'a', 'revolutionary', 'move', 'away', 'from', 'the', 'greek', 'concept', 'of', 'mathematics', 'which', 'was', 'essentially', 'geometry', 'algebra', 'was', 'a', 'unifying', 'theory', 'which', 'allowed', 'rational', 'numbers', 'irrational', 'numbers', 'geometrical', 'magnitudes', 'etc', 'to', 'all', 'be', 'treated', 'as', 'algebraic', 'objects', 'it', 'gave', 'mathematics', 'a', 'whole', 'new', 'development', 'path', 'so', 'much', 'broader', 'in', 'concept', 'to', 'that', 'which', 'had', 'existed', 'before', 'and', 'provided', 'a', 'vehicle', 'for', 'future', 'development', 'of', 'the', 'subject', 'another', 'important', 'aspect', 'of', 'the', 'introduction', 'of', 'algebraic', 'ideas', 'was', 'that', 'it', 'allowed', 'mathematics', 'to', 'be', 'applied', 'to', 'itself', 'in', 'a', 'way', 'which', 'had', 'not', 'happened', 'before']\n"
     ]
    }
   ],
   "source": [
    "def delete_punctuations(sentence):\n",
    "  sentence = sentence.lower()\n",
    "  my_clean_sentence = ''.join([item for item in sentence if item not in punctuations ])\n",
    "  return my_clean_sentence\n",
    "  \n",
    "def sentence_tokenize(text):\n",
    "  return word_tokenize(text)\n",
    "  \n",
    "tokenized_list = sentence_tokenize(delete_punctuations(txt[0]))\n",
    "print(tokenized_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8260b390",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\issam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "documentA = 'Apple Inc. is an American multinational technology company that specializes in consumer electronics, computer software, and online services. Apple is the world\\'s largest technology company by revenue and, since January 2021, the world\\'s most valuable company'\n",
    "documentB = 'Google LLC is an American multinational technology company that specializes in Internet-related services and products, which include online advertising technologies, a search engine, cloud computing, software, and hardware'\n",
    "\n",
    "nltk.download('punkt')\n",
    "tokenize_A = nltk.word_tokenize(documentA)\n",
    "tokenize_B = nltk.word_tokenize(documentB)\n",
    "uniqueWords = set(tokenize_A).union(set(tokenize_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74648dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'set'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'computer': 0,\n",
       " 'computing': 0,\n",
       " 'advertising': 0,\n",
       " 'revenue': 0,\n",
       " 'a': 0,\n",
       " '.': 0,\n",
       " 'an': 0,\n",
       " 'Inc.': 0,\n",
       " 'technologies': 0,\n",
       " 'January': 0,\n",
       " 'Apple': 0,\n",
       " 'products': 0,\n",
       " ',': 0,\n",
       " 'specializes': 0,\n",
       " 'engine': 0,\n",
       " 'world': 0,\n",
       " 'since': 0,\n",
       " 'include': 0,\n",
       " 'multinational': 0,\n",
       " 'largest': 0,\n",
       " 'the': 0,\n",
       " '2021': 0,\n",
       " 'which': 0,\n",
       " 'consumer': 0,\n",
       " 'technology': 0,\n",
       " 'search': 0,\n",
       " \"'s\": 0,\n",
       " 'American': 0,\n",
       " 'most': 0,\n",
       " 'services': 0,\n",
       " 'by': 0,\n",
       " 'LLC': 0,\n",
       " 'Google': 0,\n",
       " 'that': 0,\n",
       " 'hardware': 0,\n",
       " 'in': 0,\n",
       " 'and': 0,\n",
       " 'online': 0,\n",
       " 'is': 0,\n",
       " 'company': 0,\n",
       " 'valuable': 0,\n",
       " 'Internet-related': 0,\n",
       " 'software': 0,\n",
       " 'electronics': 0,\n",
       " 'cloud': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(uniqueWords))\n",
    "dict.fromkeys(uniqueWords, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d8e3b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'computer': 1, 'computing': 0, 'advertising': 0, 'revenue': 1, 'a': 0, '.': 1, 'an': 1, 'Inc.': 1, 'technologies': 0, 'January': 1, 'Apple': 2, 'products': 0, ',': 4, 'specializes': 1, 'engine': 0, 'world': 2, 'since': 1, 'include': 0, 'multinational': 1, 'largest': 1, 'the': 2, '2021': 1, 'which': 0, 'consumer': 1, 'technology': 2, 'search': 0, \"'s\": 2, 'American': 1, 'most': 1, 'services': 1, 'by': 1, 'LLC': 0, 'Google': 0, 'that': 1, 'hardware': 0, 'in': 1, 'and': 2, 'online': 1, 'is': 2, 'company': 3, 'valuable': 1, 'Internet-related': 0, 'software': 1, 'electronics': 1, 'cloud': 0}\n"
     ]
    }
   ],
   "source": [
    "numOfWordsA = dict.fromkeys(uniqueWords, 0)\n",
    "for word in tokenize_A:\n",
    "    numOfWordsA[word] += 1\n",
    "numOfWordsB = dict.fromkeys(uniqueWords, 0)\n",
    "for word in tokenize_B:\n",
    "    numOfWordsB[word] += 1\n",
    "print(numOfWordsA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4efef98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'computer': 0, 'computing': 1, 'advertising': 1, 'revenue': 0, 'a': 1, '.': 0, 'an': 1, 'Inc.': 0, 'technologies': 1, 'January': 0, 'Apple': 0, 'products': 1, ',': 5, 'specializes': 1, 'engine': 1, 'world': 0, 'since': 0, 'include': 1, 'multinational': 1, 'largest': 0, 'the': 0, '2021': 0, 'which': 1, 'consumer': 0, 'technology': 1, 'search': 1, \"'s\": 0, 'American': 1, 'most': 0, 'services': 1, 'by': 0, 'LLC': 1, 'Google': 1, 'that': 1, 'hardware': 1, 'in': 1, 'and': 2, 'online': 1, 'is': 1, 'company': 1, 'valuable': 0, 'Internet-related': 1, 'software': 1, 'electronics': 0, 'cloud': 1}\n"
     ]
    }
   ],
   "source": [
    "print(numOfWordsB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5e5d9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apple', 'Inc.', 'is', 'an', 'American', 'multinational', 'technology', 'company', 'that', 'specializes', 'in', 'consumer', 'electronics', ',', 'computer', 'software', ',', 'and', 'online', 'services', '.', 'Apple', 'is', 'the', 'world', \"'s\", 'largest', 'technology', 'company', 'by', 'revenue', 'and', ',', 'since', 'January', '2021', ',', 'the', 'world', \"'s\", 'most', 'valuable', 'company']\n",
      "{'computer': 1, 'computing': 0, 'advertising': 0, 'revenue': 1, 'a': 0, '.': 1, 'an': 1, 'Inc.': 1, 'technologies': 0, 'January': 1, 'Apple': 2, 'products': 0, ',': 4, 'specializes': 1, 'engine': 0, 'world': 2, 'since': 1, 'include': 0, 'multinational': 1, 'largest': 1, 'the': 2, '2021': 1, 'which': 0, 'consumer': 1, 'technology': 2, 'search': 0, \"'s\": 2, 'American': 1, 'most': 1, 'services': 1, 'by': 1, 'LLC': 0, 'Google': 0, 'that': 1, 'hardware': 0, 'in': 1, 'and': 2, 'online': 1, 'is': 2, 'company': 3, 'valuable': 1, 'Internet-related': 0, 'software': 1, 'electronics': 1, 'cloud': 0}\n"
     ]
    }
   ],
   "source": [
    "print(tokenize_A) \n",
    "print(numOfWordsA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c90d53ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'computer': 1, 'computing': 1, 'advertising': 1, 'revenue': 1, 'a': 1, '.': 1, 'an': 2, 'Inc.': 1, 'technologies': 1, 'January': 1, 'Apple': 1, 'products': 1, ',': 2, 'specializes': 2, 'engine': 1, 'world': 1, 'since': 1, 'include': 1, 'multinational': 2, 'largest': 1, 'the': 1, '2021': 1, 'which': 1, 'consumer': 1, 'technology': 2, 'search': 1, \"'s\": 1, 'American': 2, 'most': 1, 'services': 2, 'by': 1, 'LLC': 1, 'Google': 1, 'that': 2, 'hardware': 1, 'in': 2, 'and': 2, 'online': 2, 'is': 2, 'company': 2, 'valuable': 1, 'Internet-related': 1, 'software': 2, 'electronics': 1, 'cloud': 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import math\n",
    "N = len([numOfWordsA, numOfWordsB])\n",
    "    \n",
    "idfDict = dict.fromkeys([numOfWordsA, numOfWordsB][0].keys(), 0)\n",
    "k = 0\n",
    "for document in [numOfWordsA, numOfWordsB]:\n",
    "  for word, val in document.items(): \n",
    "    if val > 0:\n",
    "      idfDict[word] += 1 \n",
    "print(idfDict)  \n",
    "\n",
    "\n",
    "\n",
    "for word, val in idfDict.items():\n",
    "  idfDict[word] =  math.log(N / float(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46554512",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
